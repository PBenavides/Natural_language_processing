{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy_tutorial 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOgRaMI41iuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70rE5NXf2NEZ",
        "colab_type": "text"
      },
      "source": [
        "The tutorial link is: https://www.youtube.com/watch?v=KOCnVyxVks8\n",
        "\n",
        "#Linguistic feature extraction.\n",
        "\n",
        "But first we will define some concepts: \n",
        "\n",
        "- Tokenization: The process to segment text into words, punctuations marks, etc. \n",
        "\n",
        "- Part-of-speech Tagging: Assigning word type to tokens, like a verb or noun. \n",
        "\n",
        "- Dependency Parsing: Assigning syntactic dependecy labels, describing the relations between individual tokens like subject or object.\n",
        "\n",
        "- Lemmatization: Assigning the **base form** of a word. For example, the lemma of was is be, and the lemma of rats is rat. \n",
        "\n",
        "- Sentence Boundary Detection (SBD): Finding and segmenting individual sentences. For example, before a final dot. \n",
        "\n",
        "- Named Entity Recognition: Labelling named \"real world\" objects, like persons, companies or locations. \n",
        "\n",
        "- Entity linking (EL): Disambiguating textual entities to unique identifiers in a Knowledge Base. \n",
        "\n",
        "- Similarity: Comparing two words, for example, cat & dog are used on the same contexts. \n",
        "\n",
        "- Text Classification: Assigning categories or labels to a whole document, or parts of a document. \n",
        "\n",
        "- Rule-based Matching: Finding sequences of tokens based on their texts and linguistic annotations, similar to regex. \n",
        "\n",
        "- Serialization: Saving objects to files or byte strings. \n",
        "\n",
        "SpaCy is basically designed to receive raw data, process it and outputs a Doc Object that contains a variety of annotations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YDt3fyp1zP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Spacy has models available to implement! You can look up on: https://spacy.io/models/en\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm') #We load a small form of core web"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iSf19gC1zh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d5b83eb-79ee-4f76-8971-f9062a833420"
      },
      "source": [
        "  help(nlp)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on English in module spacy.lang.en object:\n",
            "\n",
            "class English(spacy.language.Language)\n",
            " |  A text-processing pipeline. Usually you'll load this once per process,\n",
            " |  and pass the instance around your application.\n",
            " |  \n",
            " |  Defaults (class): Settings, data and factory methods for creating the `nlp`\n",
            " |      object and processing pipeline.\n",
            " |  lang (unicode): Two-letter language ID, i.e. ISO code.\n",
            " |  \n",
            " |  DOCS: https://spacy.io/api/language\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      English\n",
            " |      spacy.language.Language\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  Defaults = <class 'spacy.lang.en.EnglishDefaults'>\n",
            " |  \n",
            " |  \n",
            " |  lang = 'en'\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from spacy.language.Language:\n",
            " |  \n",
            " |  __call__(self, text, disable=[], component_cfg=None)\n",
            " |      Apply the pipeline to some text. The text can span multiple sentences,\n",
            " |      and can contain arbtrary whitespace. Alignment into the original string\n",
            " |      is preserved.\n",
            " |      \n",
            " |      text (unicode): The text to be processed.\n",
            " |      disable (list): Names of the pipeline components to disable.\n",
            " |      component_cfg (dict): An optional dictionary with extra keyword arguments\n",
            " |          for specific components.\n",
            " |      RETURNS (Doc): A container for accessing the annotations.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#call\n",
            " |  \n",
            " |  __init__(self, vocab=True, make_doc=True, max_length=1000000, meta={}, **kwargs)\n",
            " |      Initialise a Language object.\n",
            " |      \n",
            " |      vocab (Vocab): A `Vocab` object. If `True`, a vocab is created via\n",
            " |          `Language.Defaults.create_vocab`.\n",
            " |      make_doc (callable): A function that takes text and returns a `Doc`\n",
            " |          object. Usually a `Tokenizer`.\n",
            " |      meta (dict): Custom meta data for the Language class. Is written to by\n",
            " |          models to add model meta data.\n",
            " |      max_length (int) :\n",
            " |          Maximum number of characters in a single text. The current v2 models\n",
            " |          may run out memory on extremely long texts, due to large internal\n",
            " |          allocations. You should segment these texts into meaningful units,\n",
            " |          e.g. paragraphs, subsections etc, before passing them to spaCy.\n",
            " |          Default maximum length is 1,000,000 characters (1mb). As a rule of\n",
            " |          thumb, if all pipeline components are enabled, spaCy's default\n",
            " |          models currently requires roughly 1GB of temporary memory per\n",
            " |          100,000 characters in one text.\n",
            " |      RETURNS (Language): The newly constructed object.\n",
            " |  \n",
            " |  add_pipe(self, component, name=None, before=None, after=None, first=None, last=None)\n",
            " |      Add a component to the processing pipeline. Valid components are\n",
            " |      callables that take a `Doc` object, modify it and return it. Only one\n",
            " |      of before/after/first/last can be set. Default behaviour is \"last\".\n",
            " |      \n",
            " |      component (callable): The pipeline component.\n",
            " |      name (unicode): Name of pipeline component. Overwrites existing\n",
            " |          component.name attribute if available. If no name is set and\n",
            " |          the component exposes no name attribute, component.__name__ is\n",
            " |          used. An error is raised if a name already exists in the pipeline.\n",
            " |      before (unicode): Component name to insert component directly before.\n",
            " |      after (unicode): Component name to insert component directly after.\n",
            " |      first (bool): Insert component first / not first in the pipeline.\n",
            " |      last (bool): Insert component last / not last in the pipeline.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#add_pipe\n",
            " |  \n",
            " |  begin_training(self, get_gold_tuples=None, sgd=None, component_cfg=None, **cfg)\n",
            " |      Allocate models, pre-process training data and acquire a trainer and\n",
            " |      optimizer. Used as a contextmanager.\n",
            " |      \n",
            " |      get_gold_tuples (function): Function returning gold data\n",
            " |      component_cfg (dict): Config parameters for specific components.\n",
            " |      **cfg: Config parameters.\n",
            " |      RETURNS: An optimizer.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#begin_training\n",
            " |  \n",
            " |  create_pipe(self, name, config={})\n",
            " |      Create a pipeline component from a factory.\n",
            " |      \n",
            " |      name (unicode): Factory name to look up in `Language.factories`.\n",
            " |      config (dict): Configuration parameters to initialise component.\n",
            " |      RETURNS (callable): Pipeline component.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#create_pipe\n",
            " |  \n",
            " |  disable_pipes(self, *names)\n",
            " |      Disable one or more pipeline components. If used as a context\n",
            " |      manager, the pipeline will be restored to the initial state at the end\n",
            " |      of the block. Otherwise, a DisabledPipes object is returned, that has\n",
            " |      a `.restore()` method you can use to undo your changes.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#disable_pipes\n",
            " |  \n",
            " |  evaluate(self, docs_golds, verbose=False, batch_size=256, scorer=None, component_cfg=None)\n",
            " |      Evaluate a model's pipeline components.\n",
            " |      \n",
            " |      docs_golds (iterable): Tuples of `Doc` and `GoldParse` objects.\n",
            " |      verbose (bool): Print debugging information.\n",
            " |      batch_size (int): Batch size to use.\n",
            " |      scorer (Scorer): Optional `Scorer` to use. If not passed in, a new one\n",
            " |          will be created.\n",
            " |      component_cfg (dict): An optional dictionary with extra keyword\n",
            " |          arguments for specific components.\n",
            " |      RETURNS (Scorer): The scorer containing the evaluation results.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#evaluate\n",
            " |  \n",
            " |  from_bytes(self, bytes_data, exclude=(), disable=None, **kwargs)\n",
            " |      Load state from a binary string.\n",
            " |      \n",
            " |      bytes_data (bytes): The data to load from.\n",
            " |      exclude (list): Names of components or serialization fields to exclude.\n",
            " |      RETURNS (Language): The `Language` object.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#from_bytes\n",
            " |  \n",
            " |  from_disk(self, path, exclude=(), disable=None)\n",
            " |      Loads state from a directory. Modifies the object in place and\n",
            " |      returns it. If the saved `Language` object contains a model, the\n",
            " |      model will be loaded.\n",
            " |      \n",
            " |      path (unicode or Path): A path to a directory.\n",
            " |      exclude (list): Names of components or serialization fields to exclude.\n",
            " |      RETURNS (Language): The modified `Language` object.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#from_disk\n",
            " |  \n",
            " |  get_pipe(self, name)\n",
            " |      Get a pipeline component for a given component name.\n",
            " |      \n",
            " |      name (unicode): Name of pipeline component to get.\n",
            " |      RETURNS (callable): The pipeline component.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#get_pipe\n",
            " |  \n",
            " |  has_pipe(self, name)\n",
            " |      Check if a component name is present in the pipeline. Equivalent to\n",
            " |      `name in nlp.pipe_names`.\n",
            " |      \n",
            " |      name (unicode): Name of the component.\n",
            " |      RETURNS (bool): Whether a component of the name exists in the pipeline.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#has_pipe\n",
            " |  \n",
            " |  make_doc(self, text)\n",
            " |  \n",
            " |  pipe(self, texts, as_tuples=False, n_threads=-1, batch_size=1000, disable=[], cleanup=False, component_cfg=None)\n",
            " |      Process texts as a stream, and yield `Doc` objects in order.\n",
            " |      \n",
            " |      texts (iterator): A sequence of texts to process.\n",
            " |      as_tuples (bool): If set to True, inputs should be a sequence of\n",
            " |          (text, context) tuples. Output will then be a sequence of\n",
            " |          (doc, context) tuples. Defaults to False.\n",
            " |      batch_size (int): The number of texts to buffer.\n",
            " |      disable (list): Names of the pipeline components to disable.\n",
            " |      cleanup (bool): If True, unneeded strings are freed to control memory\n",
            " |          use. Experimental.\n",
            " |      component_cfg (dict): An optional dictionary with extra keyword\n",
            " |          arguments for specific components.\n",
            " |      YIELDS (Doc): Documents in the order of the original text.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#pipe\n",
            " |  \n",
            " |  preprocess_gold(self, docs_golds)\n",
            " |      Can be called before training to pre-process gold data. By default,\n",
            " |      it handles nonprojectivity and adds missing tags to the tag map.\n",
            " |      \n",
            " |      docs_golds (iterable): Tuples of `Doc` and `GoldParse` objects.\n",
            " |      YIELDS (tuple): Tuples of preprocessed `Doc` and `GoldParse` objects.\n",
            " |  \n",
            " |  rehearse(self, docs, sgd=None, losses=None, config=None)\n",
            " |      Make a \"rehearsal\" update to the models in the pipeline, to prevent\n",
            " |      forgetting. Rehearsal updates run an initial copy of the model over some\n",
            " |      data, and update the model so its current predictions are more like the\n",
            " |      initial ones. This is useful for keeping a pre-trained model on-track,\n",
            " |      even if you're updating it with a smaller set of examples.\n",
            " |      \n",
            " |      docs (iterable): A batch of `Doc` objects.\n",
            " |      drop (float): The droput rate.\n",
            " |      sgd (callable): An optimizer.\n",
            " |      RETURNS (dict): Results from the update.\n",
            " |      \n",
            " |      EXAMPLE:\n",
            " |          >>> raw_text_batches = minibatch(raw_texts)\n",
            " |          >>> for labelled_batch in minibatch(zip(train_docs, train_golds)):\n",
            " |          >>>     docs, golds = zip(*train_docs)\n",
            " |          >>>     nlp.update(docs, golds)\n",
            " |          >>>     raw_batch = [nlp.make_doc(text) for text in next(raw_text_batches)]\n",
            " |          >>>     nlp.rehearse(raw_batch)\n",
            " |  \n",
            " |  remove_pipe(self, name)\n",
            " |      Remove a component from the pipeline.\n",
            " |      \n",
            " |      name (unicode): Name of the component to remove.\n",
            " |      RETURNS (tuple): A `(name, component)` tuple of the removed component.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#remove_pipe\n",
            " |  \n",
            " |  rename_pipe(self, old_name, new_name)\n",
            " |      Rename a pipeline component.\n",
            " |      \n",
            " |      old_name (unicode): Name of the component to rename.\n",
            " |      new_name (unicode): New name of the component.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#rename_pipe\n",
            " |  \n",
            " |  replace_pipe(self, name, component)\n",
            " |      Replace a component in the pipeline.\n",
            " |      \n",
            " |      name (unicode): Name of the component to replace.\n",
            " |      component (callable): Pipeline component.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#replace_pipe\n",
            " |  \n",
            " |  resume_training(self, sgd=None, **cfg)\n",
            " |      Continue training a pre-trained model.\n",
            " |      \n",
            " |      Create and return an optimizer, and initialize \"rehearsal\" for any pipeline\n",
            " |      component that has a .rehearse() method. Rehearsal is used to prevent\n",
            " |      models from \"forgetting\" their initialised \"knowledge\". To perform\n",
            " |      rehearsal, collect samples of text you want the models to retain performance\n",
            " |      on, and call nlp.rehearse() with a batch of Doc objects.\n",
            " |  \n",
            " |  to_bytes(self, exclude=(), disable=None, **kwargs)\n",
            " |      Serialize the current state to a binary string.\n",
            " |      \n",
            " |      exclude (list): Names of components or serialization fields to exclude.\n",
            " |      RETURNS (bytes): The serialized form of the `Language` object.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#to_bytes\n",
            " |  \n",
            " |  to_disk(self, path, exclude=(), disable=None)\n",
            " |      Save the current state to a directory.  If a model is loaded, this\n",
            " |      will include the model.\n",
            " |      \n",
            " |      path (unicode or Path): Path to a directory, which will be created if\n",
            " |          it doesn't exist.\n",
            " |      exclude (list): Names of components or serialization fields to exclude.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#to_disk\n",
            " |  \n",
            " |  update(self, docs, golds, drop=0.0, sgd=None, losses=None, component_cfg=None)\n",
            " |      Update the models in the pipeline.\n",
            " |      \n",
            " |      docs (iterable): A batch of `Doc` objects.\n",
            " |      golds (iterable): A batch of `GoldParse` objects.\n",
            " |      drop (float): The droput rate.\n",
            " |      sgd (callable): An optimizer.\n",
            " |      losses (dict): Dictionary to update with the loss, keyed by component.\n",
            " |      component_cfg (dict): Config parameters for specific pipeline\n",
            " |          components, keyed by component name.\n",
            " |      \n",
            " |      DOCS: https://spacy.io/api/language#update\n",
            " |  \n",
            " |  use_params(self, params, **cfg)\n",
            " |      Replace weights of models in the pipeline with those provided in the\n",
            " |      params dictionary. Can be used as a contextmanager, in which case,\n",
            " |      models go back to their original weights after the block.\n",
            " |      \n",
            " |      params (dict): A dictionary of parameters keyed by model ID.\n",
            " |      **cfg: Config parameters.\n",
            " |      \n",
            " |      EXAMPLE:\n",
            " |          >>> with nlp.use_params(optimizer.averages):\n",
            " |          >>>     nlp.to_disk('/tmp/checkpoint')\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from spacy.language.Language:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  entity\n",
            " |  \n",
            " |  linker\n",
            " |  \n",
            " |  matcher\n",
            " |  \n",
            " |  meta\n",
            " |  \n",
            " |  parser\n",
            " |  \n",
            " |  path\n",
            " |  \n",
            " |  pipe_names\n",
            " |      Get names of available pipeline components.\n",
            " |      \n",
            " |      RETURNS (list): List of component name strings, in order.\n",
            " |  \n",
            " |  tagger\n",
            " |  \n",
            " |  tensorizer\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from spacy.language.Language:\n",
            " |  \n",
            " |  factories = {'entity_linker': <function Language.<lambda>>, 'entity_ru...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}