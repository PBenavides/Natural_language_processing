{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semana01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRSG_71XPYvY",
        "colab_type": "text"
      },
      "source": [
        "## Notebook 001\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ggdoJtfPS_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = [\n",
        "             'Yo amo a mi perro',\n",
        "             'Yo, amo a mi gato',\n",
        "             'Yo amo a mi rana',\n",
        "             'Mi gato me ama a mi'\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsuw0zEBPbIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "75b42361-28b3-4f3d-fe82-7444797b640e"
      },
      "source": [
        "tokenizer.fit_on_texts(sentences) #fiteo mi tokenizer\n",
        "tokenizer.word_index #lo almaceno dentro de un diccionario práctico"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 2,\n",
              " 'ama': 9,\n",
              " 'amo': 4,\n",
              " 'gato': 5,\n",
              " 'me': 8,\n",
              " 'mi': 1,\n",
              " 'perro': 6,\n",
              " 'rana': 7,\n",
              " 'yo': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-eSbaZoP4zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Donde el word_index es un diccionario en el que se han encodeado las palabras\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlGjcUz3QaNC",
        "colab_type": "text"
      },
      "source": [
        "### Padding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFCVSyEfQQ4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ca211c9-d185-4332-f171-70fc7cd4f3e0"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "sequences #Es en si una lista de vectores donde cada palabra es representada por un número."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 4, 2, 1, 6], [3, 4, 2, 1, 5], [3, 4, 2, 1, 7], [1, 5, 8, 9, 2, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIEAdCgQb73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4a4c51f4-7420-4bb2-b5ec-3cef1ac95140"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\"\"\"\n",
        "Como se ve, paddear significa asignar un valor mucho más grande a esos vectores que\n",
        "de por sí anteriormente he creado. Esto porque siempre tendremos oraciones más largas que otras.\n",
        "Podemos padear de derecha a izq o viceversa. Todo dependerá de...\n",
        "\"\"\"\n",
        "padded = pad_sequences(sequences, maxlen=15)\n",
        "padded"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 2, 1, 6],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 2, 1, 5],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 2, 1, 7],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 8, 9, 2, 1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQRoBTOnRXiM",
        "colab_type": "text"
      },
      "source": [
        "### Jugando con más features del Tokenizer: \n",
        "\n",
        "\n",
        "- El parámetro oov_token nos sirve para codificar palabras que están en el test, pero que no han sido puestas inicialmente en el train. \n",
        "\n",
        "Por ejemplo, pondremos de ejemplo train_data y test_data y utilizaremos nuestro parámetro oov junto con el pad que queramos. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgz3Bmx3RKbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = [\n",
        "              'Qué bien me siento hoy',\n",
        "              'Hoy me siento masomenos',\n",
        "              'Me siento genial!',\n",
        "              'No me siento tan bien'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o3sqYNGRjUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer2 = Tokenizer(num_words=100, oov_token=\"<OOV>\")\n",
        "tokenizer2.fit_on_texts(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N61ij6JgSGoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bb718c05-f501-42f6-841e-1bddb392d8e8"
      },
      "source": [
        "#No olvidar poner el tokenizer a secuencias...\n",
        "sequences2 = tokenizer2.texts_to_sequences(train_data)\n",
        "word_index2= tokenizer2.word_index\n",
        "print(word_index2)\n",
        "#Ahora tendremos que paddearlo para que todos tengan el mimso length\n",
        "padded2 = pad_sequences(sequences2, maxlen=10)\n",
        "print(padded2)\n",
        "#Darse cuenta que el OOV está encondeado como 1, para ponerlo en el futuro test data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOV>': 1, 'me': 2, 'siento': 3, 'bien': 4, 'hoy': 5, 'qué': 6, 'masomenos': 7, 'genial': 8, 'no': 9, 'tan': 10}\n",
            "[[ 0  0  0  0  0  6  4  2  3  5]\n",
            " [ 0  0  0  0  0  0  5  2  3  7]\n",
            " [ 0  0  0  0  0  0  0  2  3  8]\n",
            " [ 0  0  0  0  0  9  2  3 10  4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anOLaXSGSMfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Crearemos nuestra data de test\n",
        "test_data = [\n",
        "             'De verdad me siento muy bien',\n",
        "             'No me siento tan bien',\n",
        "             'Me siento genial hoy'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pylv_w33TNu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f7a7cfc-198a-4740-efa6-8e05bd456f63"
      },
      "source": [
        "test_seq = tokenizer2.texts_to_sequences(test_data)\n",
        "print('\\n Test Sequence = ', test_seq)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test Sequence =  [[1, 1, 2, 3, 1, 4], [9, 2, 3, 10, 4], [2, 3, 8, 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfJx5zkPTlTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d199fbad-9d11-497c-ffab-3b8ddc00e362"
      },
      "source": [
        "test_padded = pad_sequences(test_seq, maxlen=10)\n",
        "print(test_padded)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  1  1  2  3  1  4]\n",
            " [ 0  0  0  0  0  9  2  3 10  4]\n",
            " [ 0  0  0  0  0  0  2  3  8  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-IPr_86YNT9",
        "colab_type": "text"
      },
      "source": [
        "### Jugando con data de sacarcasmo (con una competencia de kaggle) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC0_w8nOTv_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f7bcdf72-5275-4886-de61-25292ecfa624"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
        "  -O /tmp/sarcasm.json"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-04 04:14:28--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 2607:f8b0:400c:c13::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-02-04 04:14:33 (120 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmkP7VTwYToF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open(\"/tmp/sarcasm.json\",\"r\") as f:\n",
        "  datastore = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tRhg6SqaJcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "# Como la data está en json, voy a sacarla a listas para poder procesarla con mi Tokenizer\n",
        "for item in datastore:\n",
        "  sentences.append(item['headline'])\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  urls.append(item['article_link'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VidRojr3af9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_final = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer_final.fit_on_texts(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQXvrgS0bDwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "96056d2e-ba0c-4ae4-efca-4f1991e9c6fd"
      },
      "source": [
        "word_index = tokenizer_final.word_index\n",
        "print(len(word_index))\n",
        "print(\"Como se ve, el word index es muy grande. Existen muchas palabras\") "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29657\n",
            "Como se ve, el word index es muy grande. Existen muchas palabras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG-tJIFJbNlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "25903806-e983-4904-d275-1a35d95a7ac5"
      },
      "source": [
        "sequences_final = tokenizer_final.texts_to_sequences(sentences)\n",
        "#El padding = post siginifica que paddearás después, es decir, los ceros irán al final\n",
        "padded = pad_sequences(sequences_final, padding='post')\n",
        "print(sentences[10])\n",
        "print(padded[10])\n",
        "print(padded.shape,'<- Es muy grande!') "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airline passengers tackle man who rushes cockpit in bomb threat\n",
            "[2925 1680 4721   14   37 4275 6972    5 2095 1103    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "(26709, 40) <- Es muy grande!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNiMFa_4bxMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}